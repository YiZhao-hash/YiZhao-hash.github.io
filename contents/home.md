

[![YiZhao](https://img.shields.io/badge/YiZhao-GitHub-blue?logo=github)](https://github.com/YiZhao-hash/YiZhao-hash.github.io)


Hello! I am Yi Zhao, a PhD student in Computer Science at the University of Georgia (UGA). Previously, I earned my Master of Science in Engineering in Electrical Engineering from the University of Pennsylvania, graduating with a strong academic record (GPA: 3.82/4). My research interests lie at the intersection of Natural Language Processing (NLP) and Artificial Intelligence (AI), with a focus on efficient fine-tuning methods and model adaptation for large language models.

During my academic journey, I have contributed to several impactful research projects, with publications in top-tier conferences such as EMNLP and ACL. Notable works include MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning and FanLoRA: Fantastic LoRAs and Where to Find Them in Large Language Model Fine-tuning. My academic pursuits extend to practical applications, as demonstrated by my achievements in the Kaggle Happywhale competition, where I led a team to a top 2% finish.

In addition to my academic background, I gained valuable industry experience during my internship at Tencent's AI Lab, where I developed and optimized multi-label classification models and implemented efficient pre-training frameworks, making significant contributions to real-world text classification tasks.

I am proficient in various programming languages, including Python, Java, and SQL, and remain passionate about exploring cutting-edge innovations in NLP, machine learning, and AI.

#### Email
zhaoyi3[at]seas.upenn.edu

#### Education
PhD in Computer Science, University of Georgia (UGA) (Admitted: 2025)  
Master of Science in Engineering (M.S.E.), Electrical Engineering, University of Pennsylvania (2023)  
Bachelor of Engineering (B.E.), Automation, Southwest University (2019â€“2023)

#### Research Interests
Large Language Models (LLMs), Fine-tuning and Optimization of LLMs, Natural Language Processing (NLP), and Exploring Innovative Ideas in LLMs to Advance Their Efficiency, Scalability, and Real-World Applications

#### I am actively seeking collaborators who share an interest in advancing the research and applications of Large Language Models and related fields.
